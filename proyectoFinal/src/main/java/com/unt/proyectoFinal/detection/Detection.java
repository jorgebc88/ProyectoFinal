package com.unt.proyectoFinal.detection;

import java.awt.Graphics;
import java.awt.Image;
import java.awt.image.BufferedImage;
import java.io.ByteArrayInputStream;
import java.io.InputStream;

import javax.imageio.ImageIO;
import javax.swing.JFrame;
import javax.swing.JPanel;

import org.bytedeco.javacpp.opencv_core.CvPoint;
import org.bytedeco.javacpp.opencv_core.CvRect;
import org.bytedeco.javacpp.opencv_core.CvScalar;
import org.bytedeco.javacpp.opencv_core.IplImage;
import org.bytedeco.javacv.Blobs;
import org.opencv.core.Core;
import org.opencv.core.Mat;
import org.opencv.core.MatOfByte;
import org.opencv.highgui.Highgui;
import org.opencv.highgui.VideoCapture;
import org.opencv.video.BackgroundSubtractorMOG;
import org.opencv.video.BackgroundSubtractorMOG2;
import org.opencv.video.KalmanFilter;
import org.bytedeco.javacv.CanvasFrame;

import static org.bytedeco.javacpp.opencv_core.*;
import static org.bytedeco.javacpp.opencv_highgui.*;
import static org.bytedeco.javacpp.opencv_imgproc.*;




public class Detection extends JPanel{
	
	private static final long serialVersionUID = 1L;  
	 private BufferedImage image;  
	 //global variables
	 Mat frame; //current frame
	 Mat fgMaskMOG; //fg mask generated by MOG method
	 Mat fgMaskMOG2; //fg mask fg mask generated by MOG2 method
	 int keyboard;

	   // Create a constructor method  
	 public Detection(){  
		 super();  
	 }  
	 private BufferedImage getimage(){  
		 return image;  
	 }  
	 private void setimage(BufferedImage newimage){  
		 image=newimage;  
		 return;  
	 }  

  /**  
   * Converts/writes a Mat into a BufferedImage.  
   *  
   * @param matrix Mat of type CV_8UC3 or CV_8UC1  
   * @return BufferedImage of type TYPE_3BYTE_BGR or TYPE_BYTE_GRAY  
   */  
	 public static BufferedImage matToBufferedImage(Mat matrix) {  
	     int cols = matrix.cols();  
	     int rows = matrix.rows();  
	     int elemSize = (int)matrix.elemSize();  
	     byte[] data = new byte[cols * rows * elemSize];  
	     int type;  
	     matrix.get(0, 0, data);  
	     switch (matrix.channels()) {  
	       case 1:  
	         type = BufferedImage.TYPE_BYTE_GRAY;  
	         break;  
	       case 3:  
	         type = BufferedImage.TYPE_3BYTE_BGR;  
	         // bgr to rgb  
	         byte b;  
	         for(int i=0; i<data.length; i=i+3) {  
	           b = data[i];  
	           data[i] = data[i+2];  
	           data[i+2] = b;  
	         }  
	         break;  
	       default:  
	         return null;  
	     }  
	     BufferedImage image2 = new BufferedImage(cols, rows, type);  
	     image2.getRaster().setDataElements(0, 0, cols, rows, data);  
	     return image2;  
	 }  
  
//	 public void paintComponent(Graphics g){  
//		 BufferedImage temp=getimage();  
//		 g.drawImage(temp,10,10,temp.getWidth(),temp.getHeight(), this);  
//	 }
	 
	 private Image convertir(Mat imagen) {
	        MatOfByte matOfByte = new MatOfByte();
	        Highgui.imencode(".jpg", imagen, matOfByte);
	 
	        byte[] byteArray = matOfByte.toArray();
	        BufferedImage bufImage = null;
	 
	        try {
	 
	            InputStream in = new ByteArrayInputStream(byteArray);
	            bufImage = ImageIO.read(in);
	        } catch (Exception e) {
	            e.printStackTrace();
	        }
	        return (Image)bufImage;
	 }
	 
	 
	 
	 // Transforma una imagen del tipo Image a iplImage
	 private IplImage convertir2(Image image) {
		 
		 BufferedImage bufferedImage = new BufferedImage(image.getWidth(null),
		 image.getHeight(null), BufferedImage.TYPE_3BYTE_BGR /* or whatever type you like */);
		 Graphics g = bufferedImage.getGraphics();
		 g.drawImage(image, 0, 0, null);
		 g.dispose();
		 IplImage iplImage = IplImage.createFrom(bufferedImage);
		 return iplImage;
    }
	 
	 
//	 public static void Highlight(IplImage image, int [] inVec)
//	    {
//	        Highlight(image, inVec[0], inVec[1], inVec[2], inVec[3], 1);
//	    }
//	    public static void Highlight(IplImage image, int [] inVec, int Thick)
//	    {
//	        Highlight(image, inVec[0], inVec[1], inVec[2], inVec[3], Thick);
//	    }
//	    public static void Highlight(IplImage image, int xMin, int yMin, int xMax, int yMax)
//	    {
//	        Highlight(image, xMin, yMin, xMax, yMax, 1);
//	    }
//	    public static void Highlight(IplImage image, int xMin, int yMin, int xMax, int yMax, int Thick)
//	    {
//	        CvPoint pt1 = cvPoint(xMin,yMin);
//	        CvPoint pt2 = cvPoint(xMax,yMax);
//	        CvScalar color = cvScalar(255,0,0,0);       // blue [green] [red]
//	        cvRectangle(image, pt1, pt2, color, Thick, 4, 0);
//	    }  
//	 
	 
  
	 public static void main(String arg[]) throws InterruptedException{  
	    // Load the native library.  
		System.loadLibrary(Core.NATIVE_LIBRARY_NAME);
	    JFrame frame = new JFrame("BasicPanel"); 
	    JFrame frame2 = new JFrame("NotBasic"); 
	    frame.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);  
	    frame.setSize(400,400);  
	    frame2.setDefaultCloseOperation(JFrame.EXIT_ON_CLOSE);  
	    frame2.setSize(400,400);  
	    Detection prueba = new Detection();  
	    Detection prueba2 = new Detection();  
	    frame.setContentPane(prueba);       
	    frame2.setContentPane(prueba2);       
	    Mat image=new Mat();  
	    BufferedImage temp, temp2;  
	    Image temp3;
	    
	    IplImage temp4;
	    
	    BackgroundSubtractorMOG pMOG = new BackgroundSubtractorMOG(15000, 75, 0.05,0);
	    BackgroundSubtractorMOG2 pMOG2 = new BackgroundSubtractorMOG2();//1000,4,true);
	    Mat fgMaskMOG = new Mat(); //fg mask generated by MOG method
	    Mat fgMaskMOG2 = new Mat(); //fg mask fg mask generated by MOG2 method
	    KalmanFilter kf = new KalmanFilter();
	    
	    String path;
	    path = "E:Marco/ProyectoFinal/proyectoFinal/src/main/resources/video.avi";
	    Thread.sleep(500);
//	    VideoCapture capture =new VideoCapture("E:Marco/ProyectoFinal/proyectoFinal/src/main/resources/video.avi");
	    VideoCapture capture =new VideoCapture();
	    
	    //Para que funciones el VideoCapture con un video en el equipo hay q agregar 
	    //"C:\opencv\build\x64\vc12\bin" al path en las variables del sistema
//	    capture.open("video.avi");
	    capture.open(0);
//	    Thread.sleep(500);
//	    
	    
	    
	    if( capture.isOpened())
	    {
		    frame.setVisible(true);     
		    frame2.setVisible(true);       
	    	while( true )  
	    	{  
	    		capture.read(image);  
	    		if( !image.empty() )  
	    		{
	    			frame.setSize(image.width()+40,image.height()+60);  
	    			frame2.setSize(image.width()+40,image.height()+60);
	    			frame2.setLocation(700, 0);
	    			pMOG.apply(image,fgMaskMOG,0.1);
	    			temp3=prueba.convertir(fgMaskMOG);  
	    			prueba.setimage((BufferedImage)temp3); 
	    			prueba.repaint();
	    			pMOG2.apply(image,fgMaskMOG2,0.1);
	    			temp3=prueba.convertir(image);  
	    			
	    			temp4= prueba.convertir2(temp3);
	    			Blobs Blob = new Blobs();
	    			Blob.BlobAnalysis(temp4, -1, -1, -1, -1, 0,20);
	    			Blob.PrintRegionData();
		   			int BlobLabel = Blob.NextRegion(-1,0,100,500,15);
	    			System.out.println("blobLabel: [" + BlobLabel + "]");
	    			
	    			
	    			prueba2.setimage((BufferedImage)temp3); 
	    			prueba2.repaint();

	    			
	    		}  
	    		else  
	    		{  
	    			System.out.println(" --(!) No captured frame -- Break!");  
	    			break;  
	    		}  
	        }  
	    }  
	    System.out.println("NO ENTRÓ");
	    return;  
	 }  

}
